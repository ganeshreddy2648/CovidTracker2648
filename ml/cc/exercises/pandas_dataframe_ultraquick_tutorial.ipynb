{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pandas DataFrame UltraQuick Tutorial.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO_4WhdJZ5Pm",
        "cellView": "form"
      },
      "source": [
        "#@title Copyright 2020 Google LLC. Double-click here for license information.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4r2z30vJSbA"
      },
      "source": [
        "# Colabs\n",
        "\n",
        "Machine Learning Crash Course uses Colaboratories (Colabs) for all programming exercises. Colab is Google's implementation of [Jupyter Notebook](https://jupyter.org/). For more information about Colabs and how to use them, go to [Welcome to Colaboratory](https://research.google.com/colaboratory)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeKRcpe49VnV"
      },
      "source": [
        "# Pandas DataFrame UltraQuick Tutorial\n",
        "\n",
        "This Colab introduces [**DataFrames**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html), which are the central data structure in the pandas API. This Colab is not a comprehensive DataFrames tutorial.  Rather, this Colab provides a very quick introduction to the parts of DataFrames required to do the other Colab exercises in Machine Learning Crash Course.\n",
        "\n",
        "A DataFrame is similar to an in-memory spreadsheet. Like a spreadsheet:\n",
        "\n",
        "  * A DataFrame stores data in cells.\n",
        "  * A DataFrame has named columns (usually) and numbered rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AByfHsr8H_sU"
      },
      "source": [
        "## Import NumPy and pandas modules\n",
        "\n",
        "Run the following code cell to import the NumPy and pandas modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmL0l551Iibq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RutIK84wIp1S"
      },
      "source": [
        "## Creating a DataFrame\n",
        "\n",
        "The following code cell creates a simple DataFrame containing 10 cells organized as follows:\n",
        "\n",
        "  * 5 rows\n",
        "  * 2 columns, one named `temperature` and the other named `activity`\n",
        "\n",
        "The following code cell instantiates a `pd.DataFrame` class to generate a DataFrame. The class takes two arguments:\n",
        "\n",
        "  * The first argument provides the data to populate the 10 cells. The code cell calls `np.array` to generate the 5x2 NumPy array.\n",
        "  * The second argument identifies the names of the two columns.\n",
        "\n",
        "**Note**: Do not redefine variables in the following code cell. Subsequent code cells use these variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNZsPOgSD4F2"
      },
      "source": [
        "# Create and populate a 5x2 NumPy array.\n",
        "my_data = np.array([[0, 3], [10, 7], [20, 9], [30, 14], [40, 15]])\n",
        "\n",
        "# Create a Python list that holds the names of the two columns.\n",
        "my_column_names = ['temperature', 'activity']\n",
        "\n",
        "# Create a DataFrame.\n",
        "my_dataframe = pd.DataFrame(data=my_data, columns=my_column_names)\n",
        "\n",
        "# Print the entire DataFrame\n",
        "print(my_dataframe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ-I78_7OFVs"
      },
      "source": [
        "## Adding a new column to a DataFrame\n",
        "\n",
        "You may add a new column to an existing pandas DataFrame just by assigning values to a new column name. For example, the following code creates a third column named `adjusted` in `my_dataframe`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEBZyMdEOngx"
      },
      "source": [
        "# Create a new column named adjusted.\n",
        "my_dataframe[\"adjusted\"] = my_dataframe[\"activity\"] + 2\n",
        "\n",
        "# Print the entire DataFrame\n",
        "print(my_dataframe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ2aziCR5th2"
      },
      "source": [
        "## Specifying a subset of a DataFrame\n",
        "\n",
        "Pandas provide multiples ways to isolate specific rows, columns, slices or cells in a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIO91Fu65s6k"
      },
      "source": [
        "print(\"Rows #0, #1, and #2:\")\n",
        "print(my_dataframe.head(3), '\\n')\n",
        "\n",
        "print(\"Row #2:\")\n",
        "print(my_dataframe.iloc[[2]], '\\n')\n",
        "\n",
        "print(\"Rows #1, #2, and #3:\")\n",
        "print(my_dataframe[1:4], '\\n')\n",
        "\n",
        "print(\"Column 'temperature':\")\n",
        "print(my_dataframe['temperature'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cL_NxAdZzdS"
      },
      "source": [
        "## Task 1: Create a DataFrame\n",
        "\n",
        "Do the following:\n",
        "\n",
        "  1. Create an 3x4 (3 rows x 4 columns) pandas DataFrame in which the columns are named `Eleanor`,  `Chidi`, `Tahani`, and `Jason`.  Populate each of the 12 cells in the DataFrame with a random integer between 0 and 100, inclusive.\n",
        "\n",
        "  2. Output the following:\n",
        "\n",
        "     * the entire DataFrame\n",
        "     * the value in the cell of row #1 of the `Eleanor` column\n",
        "\n",
        "  3. Create a fifth column named `Janet`, which is populated with the row-by-row sums of `Tahani` and `Jason`.\n",
        "\n",
        "To complete this task, it helps to know the NumPy basics covered in the NumPy UltraQuick Tutorial.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIJEv08DMSxj"
      },
      "source": [
        "# Write your code here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPmpVM_8IoBO",
        "cellView": "form"
      },
      "source": [
        "#@title Double-click for a solution to Task 1.\n",
        "\n",
        "# Create a Python list that holds the names of the four columns.\n",
        "my_column_names = ['Eleanor', 'Chidi', 'Tahani', 'Jason']\n",
        "\n",
        "# Create a 3x4 numpy array, each cell populated with a random integer.\n",
        "my_data = np.random.randint(low=0, high=101, size=(3, 4))\n",
        "\n",
        "# Create a DataFrame.\n",
        "df = pd.DataFrame(data=my_data, columns=my_column_names)\n",
        "\n",
        "# Print the entire DataFrame\n",
        "print(df)\n",
        "\n",
        "# Print the value in row #1 of the Eleanor column.\n",
        "print(\"\\nSecond row of the Eleanor column: %d\\n\" % df['Eleanor'][1])\n",
        "\n",
        "# Create a column named Janet whose contents are the sum\n",
        "# of two other columns.\n",
        "df['Janet'] = df['Tahani'] + df['Jason']\n",
        "\n",
        "# Print the enhanced DataFrame\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh7MeyafemNL"
      },
      "source": [
        "## Copying a DataFrame (optional)\n",
        "\n",
        "Pandas provides two different ways to duplicate a DataFrame:\n",
        "\n",
        "* **Referencing.** If you assign a DataFrame to a new variable, any change to the DataFrame or to the new variable will be reflected in the other.\n",
        "* **Copying.** If you call the `pd.DataFrame.copy` method, you create a true independent copy.  Changes to the original DataFrame or to the copy will not be reflected in the other.\n",
        "\n",
        "The difference is subtle, but important."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDu2VotPgzsW"
      },
      "source": [
        "# Create a reference by assigning my_dataframe to a new variable.\n",
        "print(\"Experiment with a reference:\")\n",
        "reference_to_df = df\n",
        "\n",
        "# Print the starting value of a particular cell.\n",
        "print(\"  Starting value of df: %d\" % df['Jason'][1])\n",
        "print(\"  Starting value of reference_to_df: %d\\n\" % reference_to_df['Jason'][1])\n",
        "\n",
        "# Modify a cell in df.\n",
        "df.at[1, 'Jason'] = df['Jason'][1] + 5\n",
        "print(\"  Updated df: %d\" % df['Jason'][1])\n",
        "print(\"  Updated reference_to_df: %d\\n\\n\" % reference_to_df['Jason'][1])\n",
        "\n",
        "# Create a true copy of my_dataframe\n",
        "print(\"Experiment with a true copy:\")\n",
        "copy_of_my_dataframe = my_dataframe.copy()\n",
        "\n",
        "# Print the starting value of a particular cell.\n",
        "print(\"  Starting value of my_dataframe: %d\" % my_dataframe['activity'][1])\n",
        "print(\"  Starting value of copy_of_my_dataframe: %d\\n\" % copy_of_my_dataframe['activity'][1])\n",
        "\n",
        "# Modify a cell in df.\n",
        "my_dataframe.at[1, 'activity'] = my_dataframe['activity'][1] + 3\n",
        "print(\"  Updated my_dataframe: %d\" % my_dataframe['activity'][1])\n",
        "print(\"  copy_of_my_dataframe does not get updated: %d\" % copy_of_my_dataframe['activity'][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# -------------------------\n",
        "# Colab-friendly dataset loader\n",
        "# -------------------------\n",
        "# If you uploaded the zip via files.upload() or drag-drop, it'll usually be at:\n",
        "zip_path = \"/content/archive.zip\"\n",
        "# If you already extracted, the folder will be:\n",
        "extracted_dir = \"/content/archive\"\n",
        "\n",
        "# If zip exists and folder doesn't, extract it\n",
        "if os.path.isfile(zip_path) and not os.path.isdir(extracted_dir):\n",
        "    print(f\"Found zip at {zip_path} â€” extracting to /content ...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(\"/content\")\n",
        "    print(\"Extraction complete.\")\n",
        "elif os.path.isdir(extracted_dir):\n",
        "    print(f\"Using extracted dataset at: {extracted_dir}\")\n",
        "else:\n",
        "    # fallback: try to use keras.get_file (if you have network), otherwise raise\n",
        "    try:\n",
        "        dataset_url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "        print(\"Neither uploaded zip nor extracted folder found. Attempting keras.utils.get_file() ...\")\n",
        "        path = keras.utils.get_file(\"cats_and_dogs.zip\", origin=dataset_url, extract=True)\n",
        "        extracted_dir = os.path.join(os.path.dirname(path), \"cats_and_dogs_filtered\")\n",
        "        print(\"Downloaded and extracted to:\", extracted_dir)\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(\n",
        "            \"Dataset not found at /content. Upload 'cats_and_dogs_filtered.zip' to Colab or \"\n",
        "            \"ensure '/content/cats_and_dogs_filtered' exists. Original error: \" + str(e)\n",
        "        )\n",
        "\n",
        "# -------------------------\n",
        "# Set dataset dirs (same as your original code)\n",
        "# -------------------------\n",
        "base_dir = extracted_dir\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "\n",
        "# safe counting function\n",
        "def safe_count(folder):\n",
        "    if not os.path.isdir(folder):\n",
        "        return 0\n",
        "    return len([f for f in os.listdir(folder) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))])\n",
        "\n",
        "cats_train = safe_count(os.path.join(train_dir, \"cats\"))\n",
        "dogs_train = safe_count(os.path.join(train_dir, \"dogs\"))\n",
        "\n",
        "print(\"Train samples:\", cats_train + dogs_train)\n",
        "print(\" - Train cats:\", cats_train)\n",
        "print(\" - Train dogs:\", dogs_train)\n"
      ],
      "metadata": {
        "id": "rj3LWOnAH-q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_dir = \"/content/cats_and_dogs_filtered/cats_and_dogs_filtered\"\n",
        "base_dir = extracted_dir\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "\n",
        "# safe counting function\n",
        "def safe_count(folder):\n",
        "    if not os.path.isdir(folder):\n",
        "        return 0\n",
        "    return len([f for f in os.listdir(folder) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))])\n",
        "\n",
        "cats_train = safe_count(os.path.join(train_dir, \"cats\"))\n",
        "dogs_train = safe_count(os.path.join(train_dir, \"dogs\"))\n",
        "\n",
        "print(\"Train samples:\", cats_train + dogs_train)\n",
        "print(\" - Train cats:\", cats_train)\n",
        "print(\" - Train dogs:\", dogs_train)"
      ],
      "metadata": {
        "id": "fmmG__mfIZMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "id": "iY6qnd2eJ54v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "    keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')   # binary classification\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator\n",
        ")\n"
      ],
      "metadata": {
        "id": "d2_GLylyMxr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='validation')\n",
        "plt.legend()\n",
        "plt.title(\"Cats vs Dogs Training\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HZbALPO2QqQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = validation_dir + \"/cats/cat.2000.jpg\"  # change to any image\n",
        "img = image.load_img(img_path, target_size=(150,150))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "prediction = model.predict(img_array)[0]\n",
        "\n",
        "if prediction < 0.5:\n",
        "    print(\"Prediction: ðŸ± Cat\")\n",
        "else:\n",
        "    print(\"Prediction: ðŸ¶ Dog\")\n"
      ],
      "metadata": {
        "id": "lF_JmHy4QymW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load VGG16 without dense layers\n",
        "base_model = keras.applications.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(150, 150, 3)\n",
        ")\n",
        "\n",
        "base_model.trainable = False  # Freeze weights\n",
        "base_model.summary()\n"
      ],
      "metadata": {
        "id": "_m-1Ppx0RoDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')   # binary output\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "mFccHcXkTnAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZBFJ7ZaZVsLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PuqJi9yHVybQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}